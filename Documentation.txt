# Documentation for Personalized News Feed Agent

---

## Project Overview

This project implements a **Personalized News Feed Agent** that recommends news articles based on individual user preferences. It uses a hybrid approach combining **collaborative filtering** and **fine-tuned BERT embeddings** to generate highly relevant, dynamic recommendations. The agent adapts its suggestions over time based on user interactions (clicks, likes, skips).

---

## Approach & Model Choices

**Data Preparation:**
- Started with a publicly available news dataset (~120,000 articles).
- Cleaned and preprocessed the data using standard NLP steps (removing stopwords, lowercasing, etc.).
- Created a **sample cleaned dataset (~1,000 articles)** for fast testing on local machines.

**User Profile Modeling:**
- Simulated user interactions (likes, clicks) to model preferences.
- Used **BERT embeddings** to extract meaningful content features from each article.

**Recommendation Engine:**
- **Collaborative Filtering:**  
  Implemented a **user-based collaborative filtering** approach using cosine similarity to find articles liked by similar users.

- **Content-Based Filtering:**  
  Fine-tuned the **BERT (bert-base-uncased)** model to adapt embeddings specifically for the news dataset, improving semantic understanding.

**Personalization Logic:**
- Combined the collaborative filtering and content-based scores to generate a final ranked list of 5â€“10 articles.
- The agent dynamically updates user profiles based on simulated ongoing interactions.

---

##Code Structure

- `AI Agent 1.ipynb`:  
  - Performs EDA and data cleaning.  
  - Outputs `cleaned_data.csv`.

- `AI Agent 2.ipynb`:  
  - Fine-tunes the BERT model on the news dataset.  
  - Saves the fine-tuned model.

- `AI Agent 3.ipynb`:  
  - Loads the fine-tuned model and cleaned dataset.  
  - Generates embeddings and personalized recommendations.

---

##Dependencies

All required libraries are listed in `requirements.txt`. Key libraries include:

- `pandas`
- `numpy`
- `scikit-learn`
- `torch`
- `transformers`
- `sentence-transformers`
- `matplotlib`
- `seaborn`
- `tqdm`

---

##Instructions to Run

**Clone the Repository:**
**Install Dependencies:**
**Run the Notebooks in Order:**
- Run `AI Agent 1.ipynb` to preprocess and clean the dataset.
- Run `AI Agent 2.ipynb` to fine-tune the BERT model.
- Run `AI Agent 3.ipynb` to generate personalized recommendations.

> **Note:**  
> If you are running on a CPU, it's recommended to use the sample dataset (provided) for faster execution.

---

##Notes

- The **original cleaned dataset (~120,000 rows)** is **not uploaded** due to file size limits.
- The **sample cleaned dataset (1,000 rows)** and the **original raw dataset** are **included** in the repository.
- The **fine-tuned BERT model** is **not uploaded** (due to size) but can be regenerated by running `AI Agent 2.ipynb`.

---

##Deliverables Included

- Cleaned data (sample)
- Raw dataset
- All Jupyter notebooks
- `requirements.txt`
- Documentation files
